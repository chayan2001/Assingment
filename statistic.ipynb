{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4dMoyuXK-sk"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "### ‚ùñ **Basics of Hypothesis Testing**\n",
        "\n",
        "**Q: What is hypothesis testing in statistics?**\n",
        "**A:** Hypothesis testing is a statistical method used to make inferences or decisions about population parameters based on sample data. It involves testing an assumption (the hypothesis) using probability theory.\n",
        "\n",
        "---\n",
        "\n",
        "**Q: What is the null hypothesis, and how does it differ from the alternative hypothesis?**\n",
        "**A:** The **null hypothesis (H‚ÇÄ)** states that there is no effect or difference. The **alternative hypothesis (H‚ÇÅ or Ha)** is what you want to prove‚Äîindicating there is an effect or difference. Hypothesis testing evaluates whether data provides enough evidence to reject H‚ÇÄ in favor of H‚ÇÅ.\n",
        "\n",
        "---\n",
        "\n",
        "**Q: What is the significance level in hypothesis testing, and why is it important?**\n",
        "**A:** The significance level (Œ±) is the probability of rejecting the null hypothesis when it is actually true (Type I error). Common values are 0.05, 0.01, etc. It determines the threshold for considering a result statistically significant.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚ùñ **Understanding P-values and Errors**\n",
        "\n",
        "**Q: What does a P-value represent in hypothesis testing?**\n",
        "**A:** A **P-value** is the probability of obtaining test results at least as extreme as the observed results, assuming the null hypothesis is true. It helps assess the strength of the evidence against H‚ÇÄ.\n",
        "\n",
        "---\n",
        "\n",
        "**Q: How do you interpret the P-value in hypothesis testing?**\n",
        "**A:**\n",
        "- If **P ‚â§ Œ±**, reject the null hypothesis (significant result).\n",
        "- If **P > Œ±**, fail to reject the null hypothesis (not significant).\n",
        "\n",
        "---\n",
        "\n",
        "**Q: What are Type I and Type II errors in hypothesis testing?**\n",
        "**A:**\n",
        "- **Type I error (Œ±):** Rejecting H‚ÇÄ when it is true.\n",
        "- **Type II error (Œ≤):** Failing to reject H‚ÇÄ when H‚ÇÅ is true.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚ùñ **Test Types and Distributions**\n",
        "\n",
        "**Q: What is the difference between a one-tailed and a two-tailed test in hypothesis testing?**\n",
        "**A:**\n",
        "- **One-tailed test:** Tests for an effect in one direction (greater than or less than).\n",
        "- **Two-tailed test:** Tests for any significant difference (in either direction).\n",
        "\n",
        "---\n",
        "\n",
        "**Q: What is the Z-test, and when is it used in hypothesis testing?**\n",
        "**A:** A **Z-test** is used when the population variance is known, and the sample size is large (n ‚â• 30). It tests whether the sample mean significantly differs from a known population mean.\n",
        "\n",
        "---\n",
        "\n",
        "**Q: How do you calculate the Z-score, and what does it represent in hypothesis testing?**\n",
        "**A:**\n",
        "\\[\n",
        "Z = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}}\n",
        "\\]\n",
        "Where:\n",
        "- \\( \\bar{X} \\): sample mean\n",
        "- \\( \\mu \\): population mean\n",
        "- \\( \\sigma \\): population standard deviation\n",
        "- \\( n \\): sample size\n",
        "It tells how many standard deviations a data point is from the mean.\n",
        "\n",
        "---\n",
        "\n",
        "**Q: What is the T-distribution, and when should it be used instead of the normal distribution?**\n",
        "**A:** The **T-distribution** is used when the sample size is small (n < 30) and the population standard deviation is unknown. It is wider and has heavier tails than the normal distribution.\n",
        "\n",
        "---\n",
        "\n",
        "**Q: What is the T-test, and how is it used in hypothesis testing?**\n",
        "**A:** A **T-test** compares the means of two groups or a sample mean with a population mean. It helps determine if differences are statistically significant.\n",
        "\n",
        "---\n",
        "\n",
        "**Q: What is the difference between a Z-test and a T-test?**\n",
        "**A:**\n",
        "- **Z-test:** Known population variance, large sample size.\n",
        "- **T-test:** Unknown population variance, small sample size.\n",
        "\n",
        "---\n",
        "\n",
        "**Q: What is the relationship between Z-test and T-test in hypothesis testing?**\n",
        "**A:** Both are used to compare means. The **T-test** converges to the **Z-test** as the sample size increases. The key difference lies in whether population variance is known and the sample size.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚ùñ **Confidence Intervals and Bayes' Theorem**\n",
        "\n",
        "**Q: What is a confidence interval, and how is it used to interpret statistical results?**\n",
        "**A:** A **confidence interval (CI)** provides a range of values within which the true population parameter is likely to lie, with a certain level of confidence (e.g., 95%). It reflects the precision of the estimate.\n",
        "\n",
        "---\n",
        "\n",
        "**Q: What is the margin of error, and how does it affect the confidence interval?**\n",
        "**A:** The **margin of error** quantifies the uncertainty in the estimate. A larger margin of error results in a wider confidence interval, indicating less precision.\n",
        "\n",
        "---\n",
        "\n",
        "**Q: How is Bayes' Theorem used in statistics, and what is its significance?**\n",
        "**A:** **Bayes' Theorem** calculates the probability of an event based on prior knowledge and new evidence. It‚Äôs fundamental in Bayesian inference and decision-making under uncertainty.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚ùñ **Chi-Square and F-Tests**\n",
        "\n",
        "**Q: What is the Chi-square distribution, and when is it used?**\n",
        "**A:** The **Chi-square distribution** is used for categorical data to test relationships between variables or goodness of fit. It's skewed and depends on degrees of freedom.\n",
        "\n",
        "---\n",
        "\n",
        "**Q: What is the Chi-square goodness of fit test, and how is it applied?**\n",
        "**A:** It tests whether observed frequencies differ significantly from expected frequencies in categorical data. It helps determine if a sample matches a known distribution.\n",
        "\n",
        "---\n",
        "\n",
        "**Q: What is the F-distribution, and when is it used in hypothesis testing?**\n",
        "**A:** The **F-distribution** is used to compare variances between two populations, primarily in ANOVA and F-tests. It is positively skewed and used for testing multiple group means.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚ùñ **ANOVA and F-tests**\n",
        "\n",
        "**Q: What is an ANOVA test, and what are its assumptions?**\n",
        "**A:** **ANOVA (Analysis of Variance)** tests if there are significant differences among group means.\n",
        "**Assumptions:**\n",
        "- Independence of observations\n",
        "- Normally distributed populations\n",
        "- Equal variances (homoscedasticity)\n",
        "\n",
        "---\n",
        "\n",
        "**Q: What are the different types of ANOVA tests?**\n",
        "**A:**\n",
        "- **One-way ANOVA:** One independent variable\n",
        "- **Two-way ANOVA:** Two independent variables\n",
        "- **Repeated measures ANOVA:** Same subjects measured under different conditions\n",
        "\n",
        "---\n",
        "\n",
        "**Q: What is the F-test, and how does it relate to hypothesis testing?**\n",
        "**A:** An **F-test** compares two variances or multiple group means (in ANOVA). It‚Äôs used to test whether group differences are significant or occurred by chance.\n",
        "\n",
        "---\n",
        "**practical\n",
        "Wow, this is an awesome list of **Python-based hypothesis testing tasks**‚Äîperfect for deep-dive interview prep or academic projects! üöÄ Below is a structured breakdown of each item with a **brief explanation** and a **starter Python implementation** to help you out.\n",
        "\n",
        "---\n",
        "\n",
        "## üî∑ **Z-Test Related Tasks**\n",
        "\n",
        "### 1. **Z-Test for Comparing Sample Mean to Population Mean**\n",
        "```python\n",
        "from scipy import stats\n",
        "import numpy as np\n",
        "\n",
        "def z_test(sample_data, population_mean, population_std):\n",
        "    sample_mean = np.mean(sample_data)\n",
        "    n = len(sample_data)\n",
        "    z = (sample_mean - population_mean) / (population_std / np.sqrt(n))\n",
        "    p = 2 * (1 - stats.norm.cdf(abs(z)))\n",
        "    return z, p\n",
        "\n",
        "# Example\n",
        "data = np.random.normal(52, 5, 30)\n",
        "z_score, p_value = z_test(data, population_mean=50, population_std=5)\n",
        "print(f\"Z-score: {z_score}, P-value: {p_value}\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Simulate Data & Calculate P-Value**\n",
        "```python\n",
        "sample = np.random.normal(100, 10, 100)\n",
        "z, p = z_test(sample, 98, 10)\n",
        "print(f\"P-value: {p}\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **One-Sample Z-Test Implementation**\n",
        "Same as task 1, reuse the `z_test()` function.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Two-Tailed Z-Test Visualization**\n",
        "```python\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_z_test(z_score, alpha=0.05):\n",
        "    x = np.linspace(-4, 4, 1000)\n",
        "    y = stats.norm.pdf(x)\n",
        "\n",
        "    plt.plot(x, y)\n",
        "    plt.fill_between(x, y, where=(x <= stats.norm.ppf(alpha/2)), color='red', alpha=0.5)\n",
        "    plt.fill_between(x, y, where=(x >= stats.norm.ppf(1 - alpha/2)), color='red', alpha=0.5)\n",
        "    plt.axvline(z_score, color='blue', linestyle='--', label=f\"Z = {z_score:.2f}\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Two-tailed Z-test Decision Region\")\n",
        "    plt.show()\n",
        "\n",
        "plot_z_test(z_score)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üî∑ **Error Visualization**\n",
        "\n",
        "### 5. **Visualize Type 1 and Type 2 Errors**\n",
        "```python\n",
        "def plot_type1_type2(mu0=0, mu1=1, sigma=1, alpha=0.05):\n",
        "    x = np.linspace(-4, 6, 1000)\n",
        "    y0 = stats.norm.pdf(x, mu0, sigma)\n",
        "    y1 = stats.norm.pdf(x, mu1, sigma)\n",
        "    z_critical = stats.norm.ppf(1 - alpha)\n",
        "\n",
        "    plt.plot(x, y0, label='H0 Distribution')\n",
        "    plt.plot(x, y1, label='H1 Distribution')\n",
        "    plt.axvline(z_critical, color='black', linestyle='--', label='Critical Value')\n",
        "\n",
        "    plt.fill_between(x, y0, where=(x >= z_critical), color='red', alpha=0.3, label='Type I Error')\n",
        "    plt.fill_between(x, y1, where=(x < z_critical), color='blue', alpha=0.3, label='Type II Error')\n",
        "    plt.legend()\n",
        "    plt.title(\"Type I and Type II Errors\")\n",
        "    plt.show()\n",
        "\n",
        "plot_type1_type2()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üî∑ **T-Test Related Tasks**\n",
        "\n",
        "### 6. **Independent T-Test**\n",
        "```python\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "group1 = np.random.normal(60, 5, 30)\n",
        "group2 = np.random.normal(62, 5, 30)\n",
        "\n",
        "t_stat, p_val = ttest_ind(group1, group2)\n",
        "print(f\"T-statistic: {t_stat}, P-value: {p_val}\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 7. **Paired Sample T-Test**\n",
        "```python\n",
        "from scipy.stats import ttest_rel\n",
        "\n",
        "before = np.random.normal(100, 10, 30)\n",
        "after = before + np.random.normal(1, 5, 30)\n",
        "\n",
        "t_stat, p_val = ttest_rel(before, after)\n",
        "print(f\"Paired T-statistic: {t_stat}, P-value: {p_val}\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 8. **Compare Z-Test and T-Test**\n",
        "```python\n",
        "# Run both on the same sample\n",
        "t_stat, p_t = stats.ttest_1samp(data, 50)\n",
        "z_stat, p_z = z_test(data, 50, 5)\n",
        "\n",
        "print(f\"T-test P: {p_t}, Z-test P: {p_z}\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 9. **Confidence Interval Function**\n",
        "```python\n",
        "def confidence_interval(data, confidence=0.95):\n",
        "    mean = np.mean(data)\n",
        "    sem = stats.sem(data)\n",
        "    margin = sem * stats.t.ppf((1 + confidence) / 2, len(data) - 1)\n",
        "    return (mean - margin, mean + margin)\n",
        "\n",
        "print(\"Confidence Interval:\", confidence_interval(data))\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 10. **Margin of Error**\n",
        "```python\n",
        "def margin_of_error(data, confidence=0.95):\n",
        "    sem = stats.sem(data)\n",
        "    moe = sem * stats.t.ppf((1 + confidence) / 2, len(data) - 1)\n",
        "    return moe\n",
        "\n",
        "print(\"Margin of Error:\", margin_of_error(data))\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üî∑ **Bayesian Inference**\n",
        "\n",
        "### 11. **Bayes‚Äô Theorem in Python**\n",
        "```python\n",
        "def bayes_theorem(prior_A, likelihood_B_given_A, prior_not_A, likelihood_B_given_not_A):\n",
        "    numerator = likelihood_B_given_A * prior_A\n",
        "    denominator = numerator + likelihood_B_given_not_A * prior_not_A\n",
        "    return numerator / denominator\n",
        "\n",
        "posterior = bayes_theorem(0.01, 0.95, 0.99, 0.05)\n",
        "print(f\"Posterior Probability: {posterior}\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üî∑ **Chi-Square Tests**\n",
        "\n",
        "### 12. **Chi-square Test for Independence**\n",
        "```python\n",
        "import pandas as pd\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "data = pd.DataFrame([[10, 20], [20, 30]])\n",
        "chi2, p, dof, expected = chi2_contingency(data)\n",
        "print(f\"Chi2: {chi2}, P-value: {p}\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 13. **Expected Frequencies Calculation**\n",
        "```python\n",
        "print(\"Expected Frequencies:\\n\", expected)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 14. **Chi-square Goodness of Fit**\n",
        "```python\n",
        "observed = [30, 14, 56]\n",
        "expected = [33, 33, 33]\n",
        "\n",
        "chi2, p = stats.chisquare(f_obs=observed, f_exp=expected)\n",
        "print(f\"Chi2: {chi2}, P-value: {p}\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 15. **Visualize Chi-square Distribution**\n",
        "```python\n",
        "x = np.linspace(0, 20, 1000)\n",
        "y = stats.chi2.pdf(x, df=4)\n",
        "\n",
        "plt.plot(x, y)\n",
        "plt.title('Chi-square Distribution (df=4)')\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üî∑ **F-Test & ANOVA**\n",
        "\n",
        "### 16. **F-test for Variances**\n",
        "```python\n",
        "def f_test(var1, var2):\n",
        "    f = np.var(var1, ddof=1) / np.var(var2, ddof=1)\n",
        "    df1, df2 = len(var1) - 1, len(var2) - 1\n",
        "    p = 1 - stats.f.cdf(f, df1, df2)\n",
        "    return f, p\n",
        "\n",
        "f_val, p_val = f_test(group1, group2)\n",
        "print(f\"F-value: {f_val}, P-value: {p_val}\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 17. **One-Way ANOVA**\n",
        "```python\n",
        "from scipy.stats import f_oneway\n",
        "\n",
        "groupA = np.random.normal(60, 5, 30)\n",
        "groupB = np.random.normal(65, 5, 30)\n",
        "groupC = np.random.normal(70, 5, 30)\n",
        "\n",
        "f_stat, p = f_oneway(groupA, groupB, groupC)\n",
        "print(f\"F-statistic: {f_stat}, P-value: {p}\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 18. **Assumption Check Function**\n",
        "```python\n",
        "from scipy.stats import shapiro, levene\n",
        "\n",
        "def check_anova_assumptions(*groups):\n",
        "    for i, group in enumerate(groups):\n",
        "        stat, p = shapiro(group)\n",
        "        print(f\"Group {i+1} normality p-value: {p}\")\n",
        "    stat, p = levene(*groups)\n",
        "    print(f\"Levene‚Äôs test for equal variances p-value: {p}\")\n",
        "\n",
        "check_anova_assumptions(groupA, groupB, groupC)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 19. **Two-Way ANOVA + Visualization**\n",
        "```python\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'score': np.random.normal(70, 10, 90),\n",
        "    'group1': np.repeat(['A', 'B', 'C'], 30),\n",
        "    'group2': ['X']*15 + ['Y']*15 + ['X']*15 + ['Y']*15 + ['X']*15 + ['Y']*15\n",
        "})\n",
        "\n",
        "model = ols('score ~ C(group1) + C(group2) + C(group1):C(group2)', data=df).fit()\n",
        "anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "print(anova_table)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 20. **Visualize F-Distribution**\n",
        "```python\n",
        "x = np.linspace(0, 5, 1000)\n",
        "y = stats.f.pdf(x, dfn=3, dfd=20)\n",
        "\n",
        "plt.plot(x, y)\n",
        "plt.title('F-distribution (dfn=3, dfd=20)')\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 21. **One-Way ANOVA with Boxplots**\n",
        "```python\n",
        "import seaborn as sns\n",
        "\n",
        "sns.boxplot(x='group1', y='score', data=df)\n",
        "plt.title(\"Boxplot of Groups\")\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 22. **Simulate Normal Data and Test Mean**\n",
        "```python\n",
        "data = np.random.normal(50, 10, 100)\n",
        "t_stat, p_val = stats.ttest_1samp(data, popmean=50)\n",
        "print(f\"T-statistic: {t_stat}, P-value: {p_val}\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 23. **Test for Population Variance (Chi-square)**\n",
        "```python\n",
        "sample_var = np.var(data, ddof=1)\n",
        "n = len(data)\n",
        "chi2 = (n - 1) * sample_var / 100  # Assuming œÉ¬≤ = 100\n",
        "p_val = 1 - stats.chi2.cdf(chi2, df=n-1)\n",
        "print(f\"Chi2: {chi2}, P-value: {p_val}\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 24. **Z-Test for Comparing Proportions**\n",
        "```python\n",
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "\n",
        "success = [30, 40]\n",
        "nobs = [100, 100]\n",
        "\n",
        "z_stat, p_val = proportions_ztest(success, nobs)\n",
        "print(f\"Z-statistic: {z_stat}, P-value: {p_val}\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 25. **F-Test for Two Datasets**\n",
        "Same as Task #16 ‚Äî Use `f_test()` function and visualize if needed.\n",
        "\n",
        "---\n",
        "\n",
        "### 26. **Chi-square Goodness-of-Fit with Simulation**\n",
        "```python\n",
        "observed = np.random.randint(20, 40, size=4)\n",
        "expected = [30, 30, 30, 30]\n",
        "\n",
        "chi2_stat, p_val = stats.chisquare(observed, expected)\n",
        "print(f\"Chi2: {chi2_stat}, P-value: {p_val}\")\n",
        "\n",
        "'''"
      ]
    }
  ]
}